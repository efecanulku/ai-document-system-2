import google.generativeai as genai
import os
import json
import numpy as np
from typing import List, Dict, Optional
from dotenv import load_dotenv

load_dotenv()

class GeminiService:
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables")
        
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel('gemini-2.0-flash')
        # embedding-001 is accessed directly via genai.embed_content
    
    async def generate_summary(self, text: str) -> str:
        """Metinden √∂zet √ßƒ±kar"""
        try:
            prompt = f"""
            A≈üaƒüƒ±daki metni T√ºrk√ße olarak √∂zetle. √ñzet kƒ±sa, net ve √∂nemli noktalarƒ± i√ßermeli:
            
            {text[:4000]}  # ƒ∞lk 4000 karakteri al
            """
            
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            print(f"Summary generation error: {e}")
            return "√ñzet olu≈üturulamadƒ±."
    
    async def extract_keywords(self, text: str) -> List[str]:
        """Metinden anahtar kelimeler √ßƒ±kar"""
        try:
            prompt = f"""
            A≈üaƒüƒ±daki metinden en √∂nemli anahtar kelimeleri √ßƒ±kar. 
            Maksimum 10 anahtar kelime d√∂nd√ºr, virg√ºlle ayƒ±rarak:
            
            {text[:3000]}
            """
            
            response = self.model.generate_content(prompt)
            keywords_text = response.text.strip()
            keywords = [kw.strip() for kw in keywords_text.split(',')]
            return keywords[:10]  # Maksimum 10 anahtar kelime
        except Exception as e:
            print(f"Keywords extraction error: {e}")
            return []
    
    async def generate_embeddings(self, text: str) -> List[float]:
        """Metin i√ßin embedding vekt√∂r√º olu≈ütur"""
        try:
            # Metni par√ßalara b√∂l (embedding modeli i√ßin)
            chunks = self._split_text(text, max_length=1000)
            embeddings = []
            
            for chunk in chunks:
                response = genai.embed_content(
                    model="models/embedding-001",
                    content=chunk,
                    task_type="retrieval_document"
                )
                embeddings.append(response['embedding'])
            
            # Ortalama embedding al
            if embeddings:
                avg_embedding = np.mean(embeddings, axis=0)
                return avg_embedding.tolist()
            return []
        except Exception as e:
            print(f"Embeddings generation error: {e}")
            return []
    
    async def extract_text_from_image(self, image_path: str) -> str:
        """Resimden metin √ßƒ±kar (OCR) - Gemini Vision API kullanarak"""
        try:
            import base64
            
            # Resmi base64'e √ßevir
            with open(image_path, "rb") as image_file:
                image_data = base64.b64encode(image_file.read()).decode('utf-8')
            
            # Gemini Vision modeli kullan
            vision_model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            prompt = """
            Bu resimdeki t√ºm metni √ßƒ±kar. L√ºtfen:
            1. T√ºm yazƒ±larƒ±, sayƒ±larƒ± ve sembolleri dahil et
            2. Metni orijinal sƒ±rayla ve d√ºzende ver
            3. Tablolarƒ±, listeleri ve yapƒ±landƒ±rƒ±lmƒ±≈ü verileri koru
            4. Sadece metni ver, ek yorum yapma
            5. T√ºrk√ße karakterleri doƒüru ≈üekilde kullan
            """
            
            # Resim ve prompt'u birle≈ütir
            response = vision_model.generate_content([
                prompt,
                {
                    "mime_type": "image/jpeg" if image_path.lower().endswith('.jpg') else "image/png",
                    "data": image_data
                }
            ])
            
            extracted_text = response.text.strip()
            print(f"‚úÖ Gemini OCR ba≈üarƒ±lƒ±: {len(extracted_text)} karakter √ßƒ±karƒ±ldƒ±")
            return extracted_text
            
        except Exception as e:
            print(f"‚ùå Gemini OCR hatasƒ±: {e}")
            # Fallback olarak Tesseract kullan
            try:
                import pytesseract
                from PIL import Image
                
                print("üîÑ Tesseract fallback kullanƒ±lƒ±yor...")
                image = Image.open(image_path)
                text = pytesseract.image_to_string(image, lang='tur+eng')
                print(f"‚úÖ Tesseract fallback ba≈üarƒ±lƒ±: {len(text)} karakter √ßƒ±karƒ±ldƒ±")
                return text
                
            except Exception as fallback_error:
                print(f"‚ùå Tesseract fallback da ba≈üarƒ±sƒ±z: {fallback_error}")
                return f"Resimden metin √ßƒ±karƒ±lamadƒ±. Hata: {str(e)}"
    
    async def chat_with_context(self, question: str, context_documents: List[Dict]) -> str:
        """D√∂k√ºman baƒülamƒ±nda soru cevapla - Optimize edilmi≈ü prompt"""
        try:
            if not context_documents:
                return "Hen√ºz sisteme d√∂k√ºman y√ºklenmemi≈ü. L√ºtfen √∂nce d√∂k√ºman y√ºkleyerek sistemi eƒüitin."
            
            # En alakalƒ± chunk'larƒ± al
            relevant_chunks = []
            for doc in context_documents[:12]:  # En fazla 12 d√∂k√ºman kullan
                relevant_chunks.append({
                    'filename': doc.get('filename', 'Bilinmeyen'),
                    'content': doc.get('content_text', '')[:2000],  # Daha uzun i√ßerik
                    'summary': doc.get('summary', '')
                })
            
            # Baƒülam olu≈ütur
            context = ""
            for i, chunk in enumerate(relevant_chunks, 1):
                context += f"\n[KAYNAK {i}: {chunk['filename']}]\n"
                if chunk['summary']:
                    context += f"√ñzet: {chunk['summary']}\n"
                context += f"ƒ∞√ßerik: {chunk['content']}\n"
            
            prompt = f"""Sen uzman bir d√∂k√ºman analisti ve yardƒ±mcƒ± asistansƒ±n. G√∂revin kullanƒ±cƒ±nƒ±n sorularƒ±nƒ± yalnƒ±zca verilen kaynaklardan yanƒ±tlamaktƒ±r.

KAYNAK D√ñK√úMANLAR:
{context}

KULLANICI SORUSU: {question}

Y√ñNERGELER:
1. Yalnƒ±zca verilen kaynaklardan alƒ±ntƒ± yaparak cevap ver
2. Hangi kaynaktan alƒ±ntƒ± yaptƒ±ƒüƒ±nƒ± belirt (√∂rn: "Kaynak 1'e g√∂re...")
3. Eƒüer cevap kaynaklarda yoksa a√ßƒ±k√ßa belirt
4. Kƒ±sa, net ve T√ºrk√ße yanƒ±t ver
5. Spek√ºlasyon yapma, sadece kaynaklardaki bilgileri kullan

CEVAP:"""
            
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            print(f"Chat error: {e}")
            return "√úzg√ºn√ºm, ≈üu anda sorunuzu yanƒ±tlayamƒ±yorum."
    
    async def search_similar_documents(self, query: str, document_embeddings: List[Dict]) -> List[Dict]:
        """Query'e benzer d√∂k√ºmanlarƒ± bul"""
        try:
            # Query embedding'i olu≈ütur
            query_response = genai.embed_content(
                model="models/embedding-001",
                content=query,
                task_type="retrieval_query"
            )
            query_embedding = np.array(query_response['embedding'])
            
            # Benzerlik skorlarƒ± hesapla
            similarities = []
            for doc in document_embeddings:
                if doc.get('embeddings'):
                    doc_embedding = np.array(json.loads(doc['embeddings']))
                    similarity = np.dot(query_embedding, doc_embedding) / (
                        np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)
                    )
                    similarities.append((doc, similarity))
            
            # Skor'a g√∂re sƒ±rala
            similarities.sort(key=lambda x: x[1], reverse=True)
            
            # En benzer 5 d√∂k√ºmanƒ± d√∂nd√ºr
            return [doc for doc, score in similarities[:5] if score > 0.3]
        except Exception as e:
            print(f"Search error: {e}")
            return document_embeddings[:5]  # Fallback
    
    def _split_text(self, text: str, max_length: int = 1000) -> List[str]:
        """Metni par√ßalara b√∂l"""
        chunks = []
        words = text.split()
        current_chunk = []
        current_length = 0
        
        for word in words:
            if current_length + len(word) + 1 <= max_length:
                current_chunk.append(word)
                current_length += len(word) + 1
            else:
                if current_chunk:
                    chunks.append(' '.join(current_chunk))
                current_chunk = [word]
                current_length = len(word)
        
        if current_chunk:
            chunks.append(' '.join(current_chunk))
        
        return chunks
